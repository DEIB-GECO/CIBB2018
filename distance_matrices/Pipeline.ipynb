{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from phcnn.layers import PhyloConv1D, euclidean_distances\n",
    "\n",
    "import os\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# maximum number of cores\n",
    "n_cores = 10\n",
    "\n",
    "K.set_session(K.tf.Session(config=K.tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=n_cores, \n",
    "    inter_op_parallelism_threads=n_cores\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_path = \"/home/nanni/Data/TCGA/CIBB/BRCA/\"\n",
    "X_path = os.path.join(cancer_path, \"X.npy\")\n",
    "y_path = os.path.join(cancer_path, \"y.npy\")\n",
    "\n",
    "print(\"X_path\\t{}\".format(X_path))\n",
    "print(\"y_path\\t{}\".format(y_path))\n",
    "\n",
    "TUMOR = 0\n",
    "NORMAL = 1\n",
    "\n",
    "X = np.load(X_path)\n",
    "y = np.load(y_path)\n",
    "\n",
    "print(\"# samples: {}\\n# features: {}\".format(*X.shape))\n",
    "\n",
    "sns.countplot(y)\n",
    "plt.show()\n",
    "\n",
    "gene_symbols_path = \"/home/nanni/Data/TCGA/CIBB/gene_symbols.tsv\"\n",
    "idx_to_gene_symbol = pd.read_csv(gene_symbols_path, sep=\"\\t\", index_col=0, squeeze=True)\n",
    "gene_symbol_to_idx = pd.Series(data=idx_to_gene_symbol.index, index=idx_to_gene_symbol.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_features(X):\n",
    "    return np.arange(X.shape[1])\n",
    "    #return X.std(0).argsort()[::-1][:5000]\n",
    "\n",
    "def preprocess(X):\n",
    "    sel_features = get_filtered_features(X)\n",
    "    X_filtered = X[:, sel_features]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_filtered)\n",
    "    X_transf = scaler.transform(X_filtered)\n",
    "    \n",
    "    return X_transf, scaler, sel_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trivial_model(input_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(input_size,), activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "def create_conv_model(X_train, Y_train, nb_filters, nb_neighbors):\n",
    "    nb_features = X_train.shape[1]\n",
    "    data = Input(shape=(nb_features, 1), name=\"data\", dtype=floatx())\n",
    "    conv_layer = keras.layers.Conv1D(nb_neighbors, nb_filters, activation='relu', strides=nb_neighbors)(data)\n",
    "    # conv_layer = keras.layers.Conv1D(nb_neighbors, nb_filters, activation='relu', strides = nb_neighbors)(conv_layer)\n",
    "    flatt = Flatten()(conv_layer)\n",
    "    #drop = Dropout(0.25)(flatt)\n",
    "    #drop = Dense(units=16, activation='relu')(drop)\n",
    "    #drop = BatchNormalization()(drop)\n",
    "    # drop = Dropout(0.25)(drop)\n",
    "    output = Dense(units=Y_train.shape[1], activation=\"softmax\", name='output')(flatt)\n",
    "\n",
    "    model = Model(inputs=data, outputs=output)\n",
    "    from keras import optimizers\n",
    "    opt = optimizers.Nadam(lr=1e-4)\n",
    "    # opt = optimizers.SGD(lr = 1e-4)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "def get_early_stopping_condition(monitor=\"val_loss\", \n",
    "                                 min_delta=0, \n",
    "                                 patience=0, \n",
    "                                 mode='auto'):\n",
    "    return EarlyStopping(monitor=monitor,\n",
    "                         min_delta=min_delta,\n",
    "                         patience=patience,\n",
    "                         verbose=0,\n",
    "                         mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "n_epochs = 100\n",
    "batch_size = 60\n",
    "\n",
    "validation_split=0.25\n",
    "patience = 10\n",
    "metrics = ['accuracy']\n",
    "optimizer = \"adam\"\n",
    "loss = 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "early_stopping = get_early_stopping_condition(patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures(y_true, y_pred):\n",
    "    f1 = f1_score(y_pred=y_pred, y_true=y_true)\n",
    "    precision = precision_score(y_pred=y_pred, y_true=y_true)\n",
    "    recall = recall_score(y_pred=y_pred, y_true=y_true)\n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_true)\n",
    "    \n",
    "    return {'f1-score': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores = []\n",
    "for i_split, (train, test) in enumerate(kfold.split(X, y)):\n",
    "  \n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    X_train, scaler, sel_features = preprocess(X=X_train)\n",
    "    X_test = scaler.fit_transform(X_test[:, sel_features])\n",
    "    \n",
    "    # create the model\n",
    "    model = create_model(X_train.shape[1])\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    model.fit(X_train, y_train, \n",
    "              epochs=n_epochs, batch_size=batch_size, \n",
    "              verbose=0, validation_split=validation_split,\n",
    "              callbacks=[early_stopping])\n",
    "    # evaluate the model\n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    measures = get_measures(y_pred=y_pred, y_true=y_test)\n",
    "    measures['split'] = i_split\n",
    "    print(\"\".join([\"{:<10}{:<10.2f}\".format(k, v) for (k, v) in measures.items()]))\n",
    "    cvscores.append(measures)\n",
    "\n",
    "cvscores = pd.DataFrame.from_dict(cvscores)\n",
    "\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (deeplearning)",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
