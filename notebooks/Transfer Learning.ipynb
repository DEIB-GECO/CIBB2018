{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_selection.base import SelectorMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissues = {\n",
    "    'breast': ['BRCA'],\n",
    "    'lung': [\"LUSC\", \"LUAD\"],\n",
    "    'kidney': [\"KIRC\", \"KICH\", \"KIRP\"],\n",
    "    'bladder': ['BLCA']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast\n",
      "lung\n",
      "kidney\n",
      "bladder\n"
     ]
    }
   ],
   "source": [
    "cohorts = {}\n",
    "\n",
    "idx_to_gene, _ = src.data.load_gene_indices()\n",
    "for tissue, datasets in tissues.items():\n",
    "    print(tissue)\n",
    "    X_tissue, idx_to_sample_tissue, y_tissue = np.empty((0, idx_to_gene.shape[0])), [], np.empty(0, dtype=int)\n",
    "    for d in datasets:\n",
    "        X_d, idx_to_sample_d, _, y_d, classes = src.data.get_normal_vs_tumor_task(d)\n",
    "        X_tissue = np.vstack([X_tissue, X_d])\n",
    "        idx_to_sample_tissue = np.append(idx_to_sample_tissue, idx_to_sample_d.values)\n",
    "        y_tissue = np.append(y_tissue, y_d)\n",
    "    idx_to_sample_tissue = pd.Series(data=idx_to_sample_tissue, index=np.arange(X_tissue.shape[0], dtype=int))\n",
    "    cohorts[tissue] = (X_tissue, idx_to_sample_tissue, idx_to_gene, y_tissue, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopVariantSelector(BaseEstimator, SelectorMixin):\n",
    "    \"\"\" A very simple feature selector which uses the top variant features \"\"\"\n",
    "    def __init__(self, top_k):\n",
    "        self.top_k = top_k\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        stds = X.std(0) # 1 x n.genes\n",
    "        selected_genes = np.argsort(stds)[::-1][:self.top_k]\n",
    "        self.selected_features_ = selected_genes\n",
    "        self.mask_ = np.in1d(np.arange(X.shape[1]), selected_genes)\n",
    "        return self\n",
    "        \n",
    "    def _get_support_mask(self):\n",
    "        check_is_fitted(self, 'selected_features_')\n",
    "        check_is_fitted(self, 'mask_')\n",
    "        return self.mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix_old(y_true, y_pred, names):\n",
    "    return pd.DataFrame(data=confusion_matrix(y_true=y_true, y_pred=y_pred), \n",
    "                        index=pd.Series(names, name='Observed'), columns=pd.Series(names, name='Predicted'))\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    normal_normal, normal_tumor, tumor_normal, tumor_tumor = confusion_matrix(y_true=y_true, y_pred=y_pred).flatten()\n",
    "    cm = pd.DataFrame(data=[[normal_normal, normal_tumor, tumor_normal, tumor_tumor]], \n",
    "                      columns=['tp', 'fn', 'fp', 'tn'])\n",
    "    cm.index.name = 'true_observed'\n",
    "    return cm\n",
    "\n",
    "def sum_confusion_matrices(results_cohort):\n",
    "    r_cm = None\n",
    "    for _, cm in results_cohort.items():\n",
    "        if r_cm is None:\n",
    "            r_cm = cm\n",
    "        else:\n",
    "            r_cm += cm\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_variant = 5000\n",
    "\n",
    "def get_encoder():\n",
    "    input_layer = Input(shape=(top_variant, ))\n",
    "    h1 = Dense(500)(input_layer)\n",
    "    h2 = Dense(200, activation='relu')(Activation('relu')(BatchNormalization()(h1)))\n",
    "    h3 = Dense(100, activation='relu')((Activation('relu')(BatchNormalization()(h2))))\n",
    "    out = Dense(1, activation='sigmoid')(h3)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=out)\n",
    "    encoder = Model(inputs=input_layer, outputs=h3)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model, encoder\n",
    "\n",
    "def tumor_alone_model():\n",
    "    \"\"\" A super-simple NN for the single tumor classification\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_shape=(100, ), activation='relu'))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue = 'bladder'\n",
    "seed = 42\n",
    "n_repeated = 5\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tissue data\n",
      "Getting other tissues\n",
      "Pre-processing\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting tissue data\")\n",
    "X_tissue, _, _, y_tissue, _ = cohorts[tissue]\n",
    "\n",
    "print(\"Getting other tissues\")\n",
    "# get other tissues\n",
    "other_tissues = set(src.data.TCGA_COHORTS) - set(tissues[tissue])\n",
    "X_others, y_others = [], []\n",
    "for ot in other_tissues:\n",
    "    X_ot, _, _, y_ot, _ = src.data.get_normal_vs_tumor_task(ot)\n",
    "    X_others.append(X_ot)\n",
    "    y_others.append(y_ot)\n",
    "X_others = np.vstack(X_others)\n",
    "y_others = np.hstack(y_others)\n",
    "\n",
    "print(\"Pre-processing\")\n",
    "topvariant_selector = TopVariantSelector(top_k=top_variant)\n",
    "topvariant_selector.fit(X_tissue)\n",
    "X_tissue = topvariant_selector.transform(X_tissue)\n",
    "X_others = topvariant_selector.transform(X_others)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_tissue = scaler.fit_transform(X_tissue)\n",
    "X_others = scaler.fit_transform(X_others)\n",
    "\n",
    "X_others_train, X_other_val,\\\n",
    "y_other_train, y_other_val = train_test_split(X_others, y_others, test_size=0.3, stratify=y_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of OTHER model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 500)               2500500   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,623,701\n",
      "Trainable params: 2,622,301\n",
      "Non-trainable params: 1,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7375 samples, validate on 3162 samples\n",
      "Epoch 1/30\n",
      "7375/7375 [==============================] - 16s 2ms/sample - loss: 0.0885 - acc: 0.9698 - val_loss: 0.1510 - val_acc: 0.9639\n",
      "Epoch 2/30\n",
      "7375/7375 [==============================] - 12s 2ms/sample - loss: 0.0562 - acc: 0.9816 - val_loss: 0.4080 - val_acc: 0.8577\n",
      "Epoch 3/30\n",
      "7375/7375 [==============================] - 12s 2ms/sample - loss: 0.0400 - acc: 0.9874 - val_loss: 0.0471 - val_acc: 0.9911\n",
      "Epoch 4/30\n",
      "7375/7375 [==============================] - 11s 2ms/sample - loss: 0.0421 - acc: 0.9858 - val_loss: 0.0555 - val_acc: 0.9813\n",
      "Epoch 5/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0395 - acc: 0.9885 - val_loss: 0.0709 - val_acc: 0.9794\n",
      "Epoch 6/30\n",
      "7375/7375 [==============================] - 11s 2ms/sample - loss: 0.0320 - acc: 0.9878 - val_loss: 0.0445 - val_acc: 0.9877\n",
      "Epoch 7/30\n",
      "7375/7375 [==============================] - 11s 2ms/sample - loss: 0.0272 - acc: 0.9892 - val_loss: 0.0894 - val_acc: 0.9813\n",
      "Epoch 8/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0262 - acc: 0.9913 - val_loss: 0.0523 - val_acc: 0.9855\n",
      "Epoch 9/30\n",
      "7375/7375 [==============================] - 11s 2ms/sample - loss: 0.0217 - acc: 0.9925 - val_loss: 0.0405 - val_acc: 0.9892\n",
      "Epoch 10/30\n",
      "7375/7375 [==============================] - 11s 2ms/sample - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0454 - val_acc: 0.9902\n",
      "Epoch 11/30\n",
      "7375/7375 [==============================] - 11s 2ms/sample - loss: 0.0240 - acc: 0.9939 - val_loss: 0.0514 - val_acc: 0.9883\n",
      "Epoch 12/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0200 - acc: 0.9924 - val_loss: 0.0350 - val_acc: 0.9934\n",
      "Epoch 13/30\n",
      "7375/7375 [==============================] - 10s 1ms/sample - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0539 - val_acc: 0.9845\n",
      "Epoch 14/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0184 - acc: 0.9950 - val_loss: 0.0484 - val_acc: 0.9918\n",
      "Epoch 15/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0156 - acc: 0.9940 - val_loss: 0.0445 - val_acc: 0.9924\n",
      "Epoch 16/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0121 - acc: 0.9954 - val_loss: 0.0534 - val_acc: 0.9921\n",
      "Epoch 17/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0186 - acc: 0.9951 - val_loss: 0.0387 - val_acc: 0.9921\n",
      "Epoch 18/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0154 - acc: 0.9951 - val_loss: 0.0541 - val_acc: 0.9826\n",
      "Epoch 19/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0119 - acc: 0.9955 - val_loss: 0.0547 - val_acc: 0.9861\n",
      "Epoch 20/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0083 - acc: 0.9969 - val_loss: 0.0929 - val_acc: 0.9782\n",
      "Epoch 21/30\n",
      "7375/7375 [==============================] - 11s 1ms/sample - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0518 - val_acc: 0.9889\n",
      "Epoch 22/30\n",
      "7375/7375 [==============================] - 18s 2ms/sample - loss: 0.0091 - acc: 0.9973 - val_loss: 0.0607 - val_acc: 0.9918\n",
      "Data reduction\n"
     ]
    }
   ],
   "source": [
    "print(\"Training of OTHER model\")\n",
    "model, encoder = get_encoder()\n",
    "print(model.summary())\n",
    "model.fit(X_others_train, y_other_train, validation_data=(X_other_val, y_other_val), epochs=30, verbose=1, batch_size=10,\n",
    "          callbacks=[EarlyStopping(monitor='val_acc',restore_best_weights=True, patience=10)])\n",
    "print(\"Data reduction\")\n",
    "X_tissue = encoder.predict(X_tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for t in range(n_repeated):\n",
    "    print(\"Repetition {}\".format(t + 1))\n",
    "    skf = StratifiedKFold(n_splits=n_folds, random_state=seed + t, shuffle=True)\n",
    "    i = 0\n",
    "    for train_idx, test_idx in skf.split(X_tissue, y_tissue):\n",
    "        X_train, y_train = X_tissue[train_idx, :], y_tissue[train_idx]\n",
    "        X_test, y_test = X_tissue[test_idx, :], y_tissue[test_idx]\n",
    "        \n",
    "        print(\"\\tSplit {}\\tTrain ({}, {})\\tTest ({}, {})\".format(i, y_train[y_train == 0].shape[0], \n",
    "                                                                     y_train[y_train == 1].shape[0],\n",
    "                                                                     y_test[y_test == 0].shape[0], \n",
    "                                                                     y_test[y_test == 1].shape[0]))\n",
    "        \n",
    "        # transform target dataset\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train)\n",
    "        \n",
    "        model = tumor_alone_model()\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, verbose=1, batch_size=10,\n",
    "                  callbacks=[EarlyStopping(monitor='val_acc',restore_best_weights=True, patience=10)])\n",
    "        \n",
    "        y_pred = model.predict_classes(X_test)\n",
    "        cm_tip = get_confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        cm_tip['repetition'] = t\n",
    "        cm_tip['fold'] = i\n",
    "        results.append(cm_tip)\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>repetition</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_observed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tp  fn  fp  tn  repetition  fold\n",
       "true_observed                                  \n",
       "0               3   1   1  81           0     0\n",
       "0               3   1   0  82           0     1\n",
       "0               3   1   0  81           0     2\n",
       "0               1   3   0  81           0     3\n",
       "0               2   1   0  81           0     4\n",
       "0               2   2   0  82           1     0\n",
       "0               1   3   0  82           1     1\n",
       "0               2   2   0  81           1     2\n",
       "0               3   1   1  80           1     3\n",
       "0               3   0   0  81           1     4\n",
       "0               2   2   0  82           2     0\n",
       "0               4   0   0  82           2     1\n",
       "0               4   0   1  80           2     2\n",
       "0               4   0   2  79           2     3\n",
       "0               1   2   0  81           2     4\n",
       "0               3   1   0  82           3     0\n",
       "0               1   3   1  81           3     1\n",
       "0               4   0   0  81           3     2\n",
       "0               1   3   0  81           3     3\n",
       "0               3   0   0  81           3     4\n",
       "0               0   4   0  82           4     0\n",
       "0               3   1   1  81           4     1\n",
       "0               1   3   0  81           4     2\n",
       "0               2   2   0  81           4     3\n",
       "0               0   3   0  81           4     4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(src.reports_dir / \"confusion_matrices\" / tissue, exist_ok=True)\n",
    "results = pd.concat(results, axis=0, ignore_index=False)\n",
    "results.to_csv(src.reports_dir / \"confusion_matrices\" / tissue / \"TL.tsv\", \n",
    "                        sep=\"\\t\", index=True, header=True, index_label=\"true_predicted\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cancer_classification)",
   "language": "python",
   "name": "cancer_classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
