{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nanni/anaconda3/envs/deeplearning/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../utils/\")\n",
    "%aimport utils\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Conv1D, Flatten\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "import os\n",
    "import random as rn\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "set_random_seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "# maximum number of cores\n",
    "n_cores = 20\n",
    "\n",
    "K.set_session(K.tf.Session(config=K.tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=n_cores,\n",
    "    inter_op_parallelism_threads=n_cores\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer: KIDNEY\n",
      "\t#samples: 1020\n",
      "\t#genes: 20530\n",
      "\t#TUMORS: 891\t#NORMAL: 129\n"
     ]
    }
   ],
   "source": [
    "cancer_name = 'KIDNEY'\n",
    "X_c, y_c = utils.get_cancer_data(cancer_name)\n",
    "print(\"Cancer: {}\".format(cancer_name))\n",
    "print(\"\\t#samples: {}\".format(X_c.shape[0]))\n",
    "print(\"\\t#genes: {}\".format(X_c.shape[1]))\n",
    "print(\"\\t#TUMORS: {}\\t#NORMAL: {}\".format(y_c[y_c == utils.TUMOR].shape[0], y_c[y_c == utils.NORMAL].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_features(X):\n",
    "    return X.std(0).argsort()[::-1][:5000] # nothing happens\n",
    "\n",
    "def preprocess(X):\n",
    "    scaler = MinMaxScaler()\n",
    "    return utils.pre_process(X, get_filtered_features, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_model(input_size):\n",
    "    global stride\n",
    "    print(stride)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=5, kernel_size=(stride), input_shape=(input_size, 1), \n",
    "                     activation='relu', strides=stride))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=200, activation=\"relu\"))\n",
    "    model.add(Dense(units=50, activation=\"relu\"))\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\", name='output'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_default_1(X, y, train, test, preprocess, validation_split, seed):\n",
    "    global n_neighbors, dm\n",
    "    \n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "\n",
    "    # get the validation set in a stratified fashion from the training set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_split,\n",
    "                                                      random_state=seed, stratify=y_train)\n",
    "    print(\"Train - Test\")\n",
    "    # preprocess training set and get features and scaler\n",
    "    X_train, scaler, sel_features = preprocess(X_train)\n",
    "    print(\"Training scaled\")\n",
    "    # transform testing set\n",
    "    X_test = scaler.fit_transform(X_test[:, sel_features])\n",
    "    print(\"Test scaled\")\n",
    "    # transform validation set\n",
    "    X_val = scaler.fit_transform(X_val[:, sel_features])\n",
    "    print(\"Val scaled\")\n",
    "    oversampler = RandomOverSampler(random_state=seed)\n",
    "    \n",
    "    # oversampling\n",
    "    X_train, y_train =oversampler.fit_sample(X_train, y_train)\n",
    "    print(\"Train - oversampled\")\n",
    "    X_val, y_val = oversampler.fit_sample(X_val, y_val)\n",
    "    print(\"Val - oversampled\")\n",
    "#     print(X_train.shape)\n",
    "#     print(X_val.shape)\n",
    "\n",
    "    print(\"Filtering the distance matrix\")\n",
    "    sel_dm = dm[sel_features, :][:, sel_features]\n",
    "    sel_neighbors = np.argsort(sel_dm, axis=1)\n",
    "    conv_idxs = np.append(np.arange(sel_neighbors.shape[0]).reshape(-1, 1), sel_neighbors[:, :n_neighbors], axis=1).flatten()\n",
    "    \n",
    "    X_train = X_train[:, conv_idxs]\n",
    "    X_test = X_test[:, conv_idxs]\n",
    "    X_val = X_val[:, conv_idxs]\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], -1)\n",
    "    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], -1)\n",
    "    \n",
    "    print(\"Reshaped\")\n",
    "    print(X_train.shape)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = np.load(\"/home/nanni/Data/TCGA/CIBB/ontological_distance_matrix.npy\")\n",
    "np.fill_diagonal(dm, np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.argsort(dm, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 4\n",
    "stride = n_neighbors + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_idxs = np.append(np.arange(neighbors.shape[0]).reshape(-1, 1), neighbors[:, :n_neighbors], axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c_conv = X_c[:, conv_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Test\n",
      "Training scaled\n",
      "Test scaled\n",
      "Val scaled\n",
      "Train - oversampled\n",
      "Val - oversampled\n",
      "Filtering the distance matrix\n",
      "Reshaped\n",
      "(1068, 25000, 1)\n",
      "5\n",
      "WARNING:tensorflow:From /home/nanni/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "f1-score  1.00      precision 1.00      recall    1.00      accuracy  1.00      split     0.00      \n",
      "Train - Test\n",
      "Training scaled\n",
      "Test scaled\n",
      "Val scaled\n",
      "Train - oversampled\n",
      "Val - oversampled\n",
      "Filtering the distance matrix\n",
      "Reshaped\n",
      "(1070, 25000, 1)\n",
      "5\n",
      "f1-score  1.00      precision 1.00      recall    1.00      accuracy  1.00      split     1.00      \n",
      "Train - Test\n",
      "Training scaled\n",
      "Test scaled\n",
      "Val scaled\n",
      "Train - oversampled\n",
      "Val - oversampled\n",
      "Filtering the distance matrix\n",
      "Reshaped\n",
      "(1070, 25000, 1)\n",
      "5\n",
      "f1-score  0.98      precision 1.00      recall    0.96      accuracy  1.00      split     2.00      \n",
      "Train - Test\n",
      "Training scaled\n",
      "Test scaled\n",
      "Val scaled\n",
      "Train - oversampled\n",
      "Val - oversampled\n",
      "Filtering the distance matrix\n",
      "Reshaped\n",
      "(1070, 25000, 1)\n",
      "5\n",
      "f1-score  0.98      precision 0.96      recall    1.00      accuracy  1.00      split     3.00      \n",
      "Train - Test\n",
      "Training scaled\n",
      "Test scaled\n",
      "Val scaled\n",
      "Train - oversampled\n",
      "Val - oversampled\n",
      "Filtering the distance matrix\n",
      "Reshaped\n",
      "(1068, 25000, 1)\n",
      "5\n",
      "f1-score  1.00      precision 1.00      recall    1.00      accuracy  1.00      split     4.00      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998039</td>\n",
       "      <td>0.992305</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.992308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1-score  precision    recall\n",
       "0  0.998039  0.992305   0.992593  0.992308"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores_c, histories_c = utils.cross_validation(X=X_c, y=y_c, \n",
    "                                                 preprocess=preprocess, \n",
    "                                                 seed=seed, \n",
    "                                                 data_preparation=split_training_default_1,\n",
    "                                                 create_model=create_conv_model, \n",
    "                                                 get_measures=utils.get_measures)\n",
    "cvscores_c.mean().to_frame().T.drop(\"split\", axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (deeplearning)",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
