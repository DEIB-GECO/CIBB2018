{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils/\")\n",
    "%aimport utils\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "# reproducibility\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "set_random_seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "# maximum number of cores\n",
    "n_cores = 10\n",
    "\n",
    "K.set_session(K.tf.Session(config=K.tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=n_cores, \n",
    "    inter_op_parallelism_threads=n_cores\n",
    ")))\n",
    "\n",
    "TUMOR = 0\n",
    "NORMAL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.strftime('%Y%m%d_%H%M')\n",
    "description = \"BRCA_with_OV_UCEC_merge_NN\"\n",
    "folder = now + \"_\" + description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join(\"./results/\", folder)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.join(output_folder, \"results.xlsx\"), engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_features(X):\n",
    "    return np.arange(10)\n",
    "    #return X.std(0).argsort()[::-1][:5]\n",
    "\n",
    "def preprocess(X):\n",
    "    scaler = MinMaxScaler()\n",
    "    return utils.pre_process(X, get_filtered_features, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer: BLCA\n",
      "\t#samples: 426\n",
      "\t#genes: 20530\n",
      "\t#TUMORS: 407\t#NORMAL: 19\n"
     ]
    }
   ],
   "source": [
    "cancer_name = \"BLCA\"\n",
    "X_c, y_c = utils.get_cancer_data(cancer_name)\n",
    "print(\"Cancer: {}\".format(cancer_name))\n",
    "print(\"\\t#samples: {}\".format(X_c.shape[0]))\n",
    "print(\"\\t#genes: {}\".format(X_c.shape[1]))\n",
    "print(\"\\t#TUMORS: {}\\t#NORMAL: {}\".format(y_c[y_c == TUMOR].shape[0], y_c[y_c == NORMAL].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = X_c[:, :5000]\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_c = scaler.fit_transform(X_c.T).T\n",
    "\n",
    "oversampler = RandomUnderSampler(random_state=seed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_c, y_c, test_size=0.25, stratify=y_c)\n",
    "X_train, y_train = oversampler.fit_sample(X_train, y_train)\n",
    "\n",
    "X_test, y_test = oversampler.fit_sample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tumor_alone_model(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21 samples, validate on 7 samples\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.8462 - acc: 0.3333 - val_loss: 2.2327 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 414us/step - loss: 0.8246 - acc: 0.6667 - val_loss: 1.2236 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 352us/step - loss: 0.6132 - acc: 0.6667 - val_loss: 0.5769 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 345us/step - loss: 0.6908 - acc: 0.3333 - val_loss: 0.8667 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 329us/step - loss: 0.5853 - acc: 0.6667 - val_loss: 1.3348 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 340us/step - loss: 0.5852 - acc: 0.6667 - val_loss: 1.4354 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 347us/step - loss: 0.5859 - acc: 0.6667 - val_loss: 1.1593 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 396us/step - loss: 0.5275 - acc: 0.6667 - val_loss: 0.7851 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 392us/step - loss: 0.4985 - acc: 0.8095 - val_loss: 0.6188 - val_acc: 0.8571\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 382us/step - loss: 0.5017 - acc: 1.0000 - val_loss: 0.6718 - val_acc: 0.5714\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 385us/step - loss: 0.4626 - acc: 1.0000 - val_loss: 0.8512 - val_acc: 0.1429\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 374us/step - loss: 0.4287 - acc: 0.8095 - val_loss: 1.0129 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 342us/step - loss: 0.4223 - acc: 0.6667 - val_loss: 1.0129 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 356us/step - loss: 0.4060 - acc: 0.6667 - val_loss: 0.8560 - val_acc: 0.2857\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 362us/step - loss: 0.3735 - acc: 0.8571 - val_loss: 0.6636 - val_acc: 0.5714\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 354us/step - loss: 0.3528 - acc: 1.0000 - val_loss: 0.5494 - val_acc: 0.8571\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 370us/step - loss: 0.3454 - acc: 1.0000 - val_loss: 0.5490 - val_acc: 0.8571\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 342us/step - loss: 0.3256 - acc: 1.0000 - val_loss: 0.6315 - val_acc: 0.5714\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 351us/step - loss: 0.3011 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.5714\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 357us/step - loss: 0.2884 - acc: 0.9524 - val_loss: 0.7760 - val_acc: 0.4286\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 393us/step - loss: 0.2786 - acc: 0.9524 - val_loss: 0.7203 - val_acc: 0.5714\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 373us/step - loss: 0.2612 - acc: 0.9524 - val_loss: 0.6079 - val_acc: 0.5714\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 336us/step - loss: 0.2436 - acc: 1.0000 - val_loss: 0.5100 - val_acc: 0.8571\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 355us/step - loss: 0.2338 - acc: 1.0000 - val_loss: 0.4712 - val_acc: 0.8571\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 351us/step - loss: 0.2249 - acc: 1.0000 - val_loss: 0.5042 - val_acc: 0.8571\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 369us/step - loss: 0.2091 - acc: 1.0000 - val_loss: 0.5718 - val_acc: 0.5714\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 418us/step - loss: 0.1976 - acc: 1.0000 - val_loss: 0.6187 - val_acc: 0.5714\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 371us/step - loss: 0.1905 - acc: 1.0000 - val_loss: 0.6082 - val_acc: 0.5714\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 342us/step - loss: 0.1811 - acc: 1.0000 - val_loss: 0.5464 - val_acc: 0.7143\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 354us/step - loss: 0.1695 - acc: 1.0000 - val_loss: 0.4717 - val_acc: 0.8571\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 336us/step - loss: 0.1605 - acc: 1.0000 - val_loss: 0.4197 - val_acc: 0.8571\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 342us/step - loss: 0.1546 - acc: 1.0000 - val_loss: 0.4097 - val_acc: 0.8571\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 350us/step - loss: 0.1472 - acc: 1.0000 - val_loss: 0.4362 - val_acc: 0.8571\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 373us/step - loss: 0.1383 - acc: 1.0000 - val_loss: 0.4763 - val_acc: 0.7143\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 354us/step - loss: 0.1314 - acc: 1.0000 - val_loss: 0.5051 - val_acc: 0.7143\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 353us/step - loss: 0.1262 - acc: 1.0000 - val_loss: 0.5026 - val_acc: 0.7143\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 377us/step - loss: 0.1205 - acc: 1.0000 - val_loss: 0.4697 - val_acc: 0.7143\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 401us/step - loss: 0.1139 - acc: 1.0000 - val_loss: 0.4245 - val_acc: 0.8571\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 429us/step - loss: 0.1081 - acc: 1.0000 - val_loss: 0.3872 - val_acc: 0.8571\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 365us/step - loss: 0.1038 - acc: 1.0000 - val_loss: 0.3718 - val_acc: 0.8571\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 357us/step - loss: 0.0994 - acc: 1.0000 - val_loss: 0.3789 - val_acc: 0.8571\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 362us/step - loss: 0.0945 - acc: 1.0000 - val_loss: 0.4013 - val_acc: 0.8571\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 345us/step - loss: 0.0897 - acc: 1.0000 - val_loss: 0.4234 - val_acc: 0.8571\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 384us/step - loss: 0.0860 - acc: 1.0000 - val_loss: 0.4326 - val_acc: 0.8571\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 368us/step - loss: 0.0826 - acc: 1.0000 - val_loss: 0.4230 - val_acc: 0.8571\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 332us/step - loss: 0.0789 - acc: 1.0000 - val_loss: 0.3990 - val_acc: 0.8571\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 334us/step - loss: 0.0751 - acc: 1.0000 - val_loss: 0.3717 - val_acc: 0.8571\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 333us/step - loss: 0.0719 - acc: 1.0000 - val_loss: 0.3521 - val_acc: 0.8571\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 359us/step - loss: 0.0691 - acc: 1.0000 - val_loss: 0.3458 - val_acc: 0.8571\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 288us/step - loss: 0.0663 - acc: 1.0000 - val_loss: 0.3520 - val_acc: 0.8571\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 299us/step - loss: 0.0633 - acc: 1.0000 - val_loss: 0.3653 - val_acc: 0.8571\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 301us/step - loss: 0.0606 - acc: 1.0000 - val_loss: 0.3766 - val_acc: 0.8571\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 312us/step - loss: 0.0582 - acc: 1.0000 - val_loss: 0.3797 - val_acc: 0.8571\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 328us/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.3727 - val_acc: 0.8571\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 316us/step - loss: 0.0537 - acc: 1.0000 - val_loss: 0.3581 - val_acc: 0.8571\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 286us/step - loss: 0.0515 - acc: 1.0000 - val_loss: 0.3413 - val_acc: 0.8571\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 304us/step - loss: 0.0494 - acc: 1.0000 - val_loss: 0.3288 - val_acc: 0.8571\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0476 - acc: 1.0000 - val_loss: 0.3231 - val_acc: 0.8571\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 332us/step - loss: 0.0458 - acc: 1.0000 - val_loss: 0.3243 - val_acc: 0.8571\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 292us/step - loss: 0.0440 - acc: 1.0000 - val_loss: 0.3302 - val_acc: 0.8571\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 319us/step - loss: 0.0423 - acc: 1.0000 - val_loss: 0.3362 - val_acc: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 321us/step - loss: 0.0407 - acc: 1.0000 - val_loss: 0.3391 - val_acc: 0.8571\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 301us/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.3372 - val_acc: 0.8571\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 313us/step - loss: 0.0378 - acc: 1.0000 - val_loss: 0.3305 - val_acc: 0.8571\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 324us/step - loss: 0.0365 - acc: 1.0000 - val_loss: 0.3211 - val_acc: 0.8571\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 330us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.3115 - val_acc: 0.8571\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 300us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.3039 - val_acc: 0.8571\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 380us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.3008 - val_acc: 0.8571\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 295us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.8571\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 275us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.3053 - val_acc: 0.8571\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 321us/step - loss: 0.0295 - acc: 1.0000 - val_loss: 0.3085 - val_acc: 0.8571\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 335us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.3095 - val_acc: 0.8571\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 308us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.3075 - val_acc: 0.8571\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 318us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.8571\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 360us/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.2960 - val_acc: 0.8571\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 383us/step - loss: 0.0250 - acc: 1.0000 - val_loss: 0.2896 - val_acc: 0.8571\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 389us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.2859 - val_acc: 0.8571\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 373us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.2850 - val_acc: 0.8571\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 337us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.2862 - val_acc: 0.8571\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 356us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.2882 - val_acc: 0.8571\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 375us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.2886 - val_acc: 0.8571\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 302us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.2869 - val_acc: 0.8571\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 345us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.2834 - val_acc: 0.8571\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 288us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.2786 - val_acc: 0.8571\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 299us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.2740 - val_acc: 0.8571\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 318us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.2702 - val_acc: 0.8571\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 316us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.2684 - val_acc: 0.8571\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 315us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.2684 - val_acc: 0.8571\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 346us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.2689 - val_acc: 0.8571\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 347us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.2694 - val_acc: 0.8571\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 292us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.2693 - val_acc: 0.8571\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 319us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.2685 - val_acc: 0.8571\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 268us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.2671 - val_acc: 0.8571\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 331us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.2652 - val_acc: 0.8571\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 355us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.2629 - val_acc: 0.8571\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 306us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.2603 - val_acc: 0.8571\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 335us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.2578 - val_acc: 0.8571\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 293us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.2561 - val_acc: 0.8571\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 292us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.2553 - val_acc: 0.8571\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 303us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.2549 - val_acc: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe6a829d68>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split=0.25, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888888888888889"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [1, 4]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#others = list(set(utils.all_tumor_names) - {cancer_name})\n",
    "others = ['UCEC', 'OV']\n",
    "# print(\", \".join(others))\n",
    "\n",
    "X_others = np.empty((0, X_c.shape[1]), dtype=int)\n",
    "y_others = np.empty(0, dtype=int)\n",
    "\n",
    "for o in others:\n",
    "    print(o)\n",
    "    X_o, y_o = utils.get_cancer_data(o)\n",
    "    X_others = np.append(X_others, X_o, axis=0)\n",
    "    y_others = np.append(y_others, y_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tumor alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tumor_alone_model(input_size):\n",
    "    \"\"\" A super-simple NN for the single tumor classification\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(input_size,), activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores_c, histories_c = utils.cross_validation(X=X_c, y=y_c, preprocess=preprocess, seed=seed,\n",
    "                                    create_model=tumor_alone_model, get_measures=utils.get_measures)\n",
    "cvscores_c.mean().to_frame().T.drop(\"split\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.report(cvscores_c, writer=writer, sheet_name=\"{}_alone\".format(cancer_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def others_alone_model(input_size):\n",
    "    h1 = 500\n",
    "    h2 = 200\n",
    "    h3 = 100\n",
    "    h4 = 50\n",
    "    out = 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1, input_shape=(input_size, ), activation=\"relu\"))\n",
    "    model.add(Dense(h2, activation=\"relu\"))\n",
    "    model.add(Dense(h3, activation=\"relu\"))\n",
    "    model.add(Dense(h4, activation=\"relu\"))\n",
    "    model.add(Dense(out, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores_others, histories_others = utils.cross_validation(X=X_others, y=y_others, preprocess=preprocess, \n",
    "                                                           seed=seed, create_model=others_alone_model, \n",
    "                                                           get_measures=utils.get_measures)\n",
    "cvscores_others.mean().to_frame().T.drop(\"split\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.report(cvscores_others, writer=writer, sheet_name=\"{}_others\".format(cancer_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_other_network(input_size):\n",
    "    h1 = 500\n",
    "    h2 = 200\n",
    "    h3 = 100\n",
    "    h4 = 50\n",
    "    out = 1\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1, input_shape=(input_size, ), activation=\"relu\", name='h1'))\n",
    "    model.add(Dense(h2, activation=\"relu\", name='h2'))\n",
    "    model.add(Dense(h3, activation=\"relu\", name='h3'))\n",
    "    model.add(Dense(h4, activation=\"relu\", name='h4'))\n",
    "    model.add(Dense(out, activation=\"sigmoid\", name='out'))\n",
    "    \n",
    "    encoder = Model(inputs=model.input, outputs=model.get_layer(\"h3\").output)\n",
    "    \n",
    "    return model, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_additional_network(input_size):\n",
    "    h1 = 50\n",
    "    h2 = 10\n",
    "    out = 1\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(h1, input_shape=(input_size, ), activation=\"relu\", name='h1'))\n",
    "    model.add(Dense(h2, activation=\"relu\", name='h2'))\n",
    "    model.add(Dense(out, activation=\"sigmoid\", name='out'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def tl_data_merging(X, y, train, test, preprocess, validation_split, seed, X_other, y_other):\n",
    "\n",
    "#     print(X.shape, y.shape)\n",
    "#     print(X_other.shape, y.shape)\n",
    "#     print(\"Splitting of X_c\")\n",
    "    \n",
    "    # Splitting the single tumor dataset\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    # get the validation set in a stratified fashion from the training set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_split,\n",
    "                                                      random_state=seed, stratify=y_train)\n",
    "    # Merge the single cancer training set with the other set\n",
    "    X_train_merged = np.append(X_train, X_other, axis=0)\n",
    "    y_train_merged = np.append(y_train, y_other)\n",
    "    \n",
    "    # preprocess merged training set and get features and scaler\n",
    "    X_train_merged, scaler, sel_features = preprocess(X_train_merged)\n",
    "    # transform testing set\n",
    "    X_test = scaler.fit_transform(X_test[:, sel_features])\n",
    "    # transform validation set\n",
    "    X_val = scaler.fit_transform(X_val[:, sel_features])\n",
    "\n",
    "#     print(X_train_merged.shape, y_train_merged.shape)\n",
    "#     print(X_val.shape, y_val.shape)\n",
    "#     print(X_test.shape, y_test.shape)\n",
    "    \n",
    "    return X_train_merged, X_val, X_test, y_train_merged, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def transfer_learning(X, y, train, test, preprocess, validation_split, seed, X_other, y_other):\n",
    "#     print(X.shape, y.shape)\n",
    "#     print(X_other.shape, y.shape)\n",
    "#     print(\"Splitting of X_c\")\n",
    "    # Splitting the single tumor dataset\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    # get the validation set in a stratified fashion from the training set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_split,\n",
    "                                                      random_state=seed, stratify=y_train)\n",
    "#     print(\"Scaling of X_c\")\n",
    "    # preprocess training set and get features and scaler\n",
    "    X_train, scaler, sel_features = preprocess(X_train)\n",
    "    # transform testing set\n",
    "    X_test = scaler.fit_transform(X_test[:, sel_features])\n",
    "    # transform validation set\n",
    "    X_val = scaler.fit_transform(X_val[:, sel_features])\n",
    "    \n",
    "#     print(\"Scaling and selection on X_other\")\n",
    "    # for the other set we use a brand new scaler but the same features\n",
    "    other_scaler = MinMaxScaler()\n",
    "    X_other = other_scaler.fit_transform(X_other[:, sel_features])\n",
    "    # splitting other set in training and validation (no test...useless)\n",
    "    X_other_train, X_other_val, \\\n",
    "    y_other_train, y_other_val = train_test_split(X_other, y_other, test_size=validation_split,\n",
    "                                                  random_state=seed, stratify=y_other)\n",
    "    \n",
    "#     print(\"Fitting the OTHER model\")\n",
    "    # create and fit the OTHER model\n",
    "    other_model, encoder = create_other_network(input_size=X_other_train.shape[1])\n",
    "    other_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    other_model.fit(X_other_train, y_other_train,\n",
    "                    epochs=100, batch_size=60,\n",
    "                    verbose=0, validation_data=(X_other_val, y_other_val),\n",
    "                    callbacks=[utils.get_early_stopping_condition()])\n",
    "    \n",
    "#     print(\"Encoding X_c\")\n",
    "    # embedding of data\n",
    "    X_train_code = encoder.predict(X_train)\n",
    "    X_val_code = encoder.predict(X_val)\n",
    "    X_test_code = encoder.predict(X_test)\n",
    "    \n",
    "#     print(X_train_code.shape)\n",
    "#     print(X_val_code.shape)\n",
    "#     print(X_test_code.shape)\n",
    "    \n",
    "    return X_train_code, X_val_code, X_test_code, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores_tl, histories_tl = utils.cross_validation(X=X_c, y=y_c, preprocess=preprocess, seed=seed,\n",
    "                                                   create_model=others_alone_model, \n",
    "                                                   get_measures=utils.get_measures, \n",
    "                                                   data_preparation=tl_data_merging, \n",
    "                                                   X_other=X_others, y_other=y_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores_tl, histories_tl = utils.cross_validation(X=X_c, y=y_c, preprocess=preprocess, seed=seed,\n",
    "                                                   create_model=create_additional_network, \n",
    "                                                   get_measures=utils.get_measures, \n",
    "                                                   data_preparation=transfer_learning, \n",
    "                                                   X_other=X_others, y_other=y_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores_tl.mean().to_frame().T.drop(\"split\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.report(cvscores_others, writer=writer, sheet_name=\"{}_TL\".format(cancer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (deeplearning)",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
